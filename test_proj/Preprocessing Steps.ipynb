{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039efcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "# Create feature\n",
    "feature = np.array([\n",
    "    [\"Texas\"],\n",
    "    [\"California\"],\n",
    "    [\"Texas\"],\n",
    "    [\"Delaware\"],\n",
    "    [\"Texas\"]])\n",
    "# Create one-hot encoder\n",
    "one_hot = LabelBinarizer()\n",
    "# One-hot encode feature\n",
    "\n",
    "one_hot.fit_transform(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ac214a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e68ae8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Texas', 'California', 'Texas', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reverse one-hot encoding\n",
    "one_hot.inverse_transform(one_hot.transform(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ae3f5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "# Create features\n",
    "dataframe = pd.DataFrame({\"Score\": [\"Low\", \"Low\", \"Medium\", \"Medium\", \"High\"]})\n",
    "\n",
    "# Create mapper\n",
    "scale_mapper = {\n",
    "    \"Low\":1,\n",
    "    \"Medium\":2,\n",
    "    \"High\":3\n",
    "}\n",
    "# Replace feature values with scale\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6bcc681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 1.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create feature matrix with categorical feature\n",
    "X = np.array([\n",
    "    [0, 2.10, 1.45],\n",
    "    [1, 1.18, 1.33],\n",
    "    [0, 1.22, 1.27],\n",
    "    [1, -0.21, -1.19]\n",
    "])\n",
    "\n",
    "# Create feature matrix with missing values in the categorical feature\n",
    "X_with_nan = np.array([\n",
    "    [np.nan, 0.87, 1.31],\n",
    "    [np.nan, -0.67, -0.22]\n",
    "])\n",
    "\n",
    "# Train KNN learner\n",
    "clf = KNeighborsClassifier(3, weights='distance')\n",
    "trained_model = clf.fit(X[:,1:], X[:,0])\n",
    "\n",
    "# Predict missing values' class\n",
    "imputed_values = trained_model.predict(X_with_nan[:,1:])\n",
    "\n",
    "# Join column of predicted class with their other features\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:]))\n",
    "\n",
    "# Join two feature matrices\n",
    "np.vstack((X_with_imputed, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53792764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 0.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.preprocessing import Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Join the two feature matrices\n",
    "X_complete = np.vstack((X_with_nan, X))\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567abc99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
