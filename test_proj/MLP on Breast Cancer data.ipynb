{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e441a403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                310       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 431\n",
      "Trainable params: 431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "{'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 30), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'dense_input'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'batch_input_shape': (None, 30), 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 27ms/step - loss: 3325.9651 - mse: 3325.9651 - val_loss: 1074.1571 - val_mse: 1074.1571\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 695.0460 - mse: 695.0460 - val_loss: 69.7738 - val_mse: 69.7738\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 159.7306 - mse: 159.7306 - val_loss: 219.6831 - val_mse: 219.6831\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 295.7543 - mse: 295.7543 - val_loss: 184.7921 - val_mse: 184.7921\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 171.2974 - mse: 171.2974 - val_loss: 54.1754 - val_mse: 54.1754\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 91.7962 - mse: 91.7962 - val_loss: 49.3166 - val_mse: 49.3166\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 97.3000 - mse: 97.3000 - val_loss: 49.3097 - val_mse: 49.3097\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 85.4700 - mse: 85.4700 - val_loss: 36.8708 - val_mse: 36.8708\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 72.7160 - mse: 72.7160 - val_loss: 39.6633 - val_mse: 39.6633\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 70.0095 - mse: 70.0095 - val_loss: 36.1025 - val_mse: 36.1025\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 63.2167 - mse: 63.2167 - val_loss: 29.9575 - val_mse: 29.9575\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 62.2102 - mse: 62.2102 - val_loss: 27.9390 - val_mse: 27.9390\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 59.4672 - mse: 59.4672 - val_loss: 28.3687 - val_mse: 28.3687\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 53.7803 - mse: 53.7803 - val_loss: 25.0353 - val_mse: 25.0353\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 49.1590 - mse: 49.1590 - val_loss: 22.0760 - val_mse: 22.0760\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 46.0869 - mse: 46.0869 - val_loss: 20.3092 - val_mse: 20.3092\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 42.3982 - mse: 42.3982 - val_loss: 20.9140 - val_mse: 20.9140\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 40.2296 - mse: 40.2296 - val_loss: 18.5362 - val_mse: 18.5362\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 36.5597 - mse: 36.5597 - val_loss: 15.5678 - val_mse: 15.5678\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 35.4375 - mse: 35.4375 - val_loss: 14.4959 - val_mse: 14.4959\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 31.2339 - mse: 31.2339 - val_loss: 14.4179 - val_mse: 14.4179\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 30.7149 - mse: 30.7149 - val_loss: 13.8188 - val_mse: 13.8188\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 27.0025 - mse: 27.0025 - val_loss: 11.4528 - val_mse: 11.4528\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 27.2237 - mse: 27.2237 - val_loss: 10.6947 - val_mse: 10.6947\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 24.0494 - mse: 24.0494 - val_loss: 11.0489 - val_mse: 11.0489\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 22.0478 - mse: 22.0478 - val_loss: 9.8023 - val_mse: 9.8023\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 20.4481 - mse: 20.4481 - val_loss: 8.5124 - val_mse: 8.5124\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 18.9618 - mse: 18.9618 - val_loss: 8.0673 - val_mse: 8.0673\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 17.1236 - mse: 17.1236 - val_loss: 7.4771 - val_mse: 7.4771\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 16.0370 - mse: 16.0370 - val_loss: 6.8369 - val_mse: 6.8369\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 14.9700 - mse: 14.9700 - val_loss: 6.4992 - val_mse: 6.4992\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 13.5456 - mse: 13.5456 - val_loss: 6.1413 - val_mse: 6.1413\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 12.6846 - mse: 12.6846 - val_loss: 5.6710 - val_mse: 5.6710\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 11.7047 - mse: 11.7047 - val_loss: 5.4790 - val_mse: 5.4790\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 10.8983 - mse: 10.8983 - val_loss: 4.9874 - val_mse: 4.9874\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 10.0290 - mse: 10.0290 - val_loss: 4.7419 - val_mse: 4.7419\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 9.2606 - mse: 9.2606 - val_loss: 4.7568 - val_mse: 4.7568\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 9.3600 - mse: 9.3600 - val_loss: 4.4754 - val_mse: 4.4754\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 8.0715 - mse: 8.0715 - val_loss: 4.0873 - val_mse: 4.0873\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 7.4798 - mse: 7.4798 - val_loss: 4.3125 - val_mse: 4.3125\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 6.9892 - mse: 6.9892 - val_loss: 3.7903 - val_mse: 3.7903\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 6.5554 - mse: 6.5554 - val_loss: 3.6937 - val_mse: 3.6937\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 6.1868 - mse: 6.1868 - val_loss: 3.5969 - val_mse: 3.5969\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 5.8917 - mse: 5.8917 - val_loss: 3.5232 - val_mse: 3.5232\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 5.7701 - mse: 5.7701 - val_loss: 3.4069 - val_mse: 3.4069\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 5.5027 - mse: 5.5027 - val_loss: 3.3653 - val_mse: 3.3653\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 5.2513 - mse: 5.2513 - val_loss: 3.2136 - val_mse: 3.2136\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 5.0666 - mse: 5.0666 - val_loss: 3.1172 - val_mse: 3.1172\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.9139 - mse: 4.9139 - val_loss: 3.0476 - val_mse: 3.0476\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.6635 - mse: 4.6635 - val_loss: 2.9313 - val_mse: 2.9313\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.5165 - mse: 4.5165 - val_loss: 2.8763 - val_mse: 2.8763\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.3825 - mse: 4.3825 - val_loss: 2.8002 - val_mse: 2.8002\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.2165 - mse: 4.2165 - val_loss: 2.7455 - val_mse: 2.7455\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.1492 - mse: 4.1492 - val_loss: 2.7151 - val_mse: 2.7151\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.9533 - mse: 3.9533 - val_loss: 2.6704 - val_mse: 2.6704\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.8360 - mse: 3.8360 - val_loss: 2.6340 - val_mse: 2.6340\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.0908 - mse: 4.0908 - val_loss: 2.6897 - val_mse: 2.6897\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.6826 - mse: 3.6826 - val_loss: 2.6469 - val_mse: 2.6469\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.5716 - mse: 3.5717 - val_loss: 2.5937 - val_mse: 2.5937\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.4872 - mse: 3.4872 - val_loss: 2.5518 - val_mse: 2.5518\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.4863 - mse: 3.4863 - val_loss: 2.4902 - val_mse: 2.4902\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.2979 - mse: 3.2979 - val_loss: 2.4226 - val_mse: 2.4226\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.2286 - mse: 3.2286 - val_loss: 2.3816 - val_mse: 2.3816\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.2212 - mse: 3.2212 - val_loss: 2.3364 - val_mse: 2.3364\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.0897 - mse: 3.0897 - val_loss: 2.2835 - val_mse: 2.2835\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.0971 - mse: 3.0971 - val_loss: 2.2681 - val_mse: 2.2681\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.0005 - mse: 3.0005 - val_loss: 2.2928 - val_mse: 2.2928\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.0043 - mse: 3.0043 - val_loss: 2.2256 - val_mse: 2.2256\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.9107 - mse: 2.9107 - val_loss: 2.1725 - val_mse: 2.1725\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.1650 - mse: 3.1650 - val_loss: 2.1691 - val_mse: 2.1691\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.9239 - mse: 2.9239 - val_loss: 2.1304 - val_mse: 2.1304\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.8256 - mse: 2.8256 - val_loss: 2.2477 - val_mse: 2.2477\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.9264 - mse: 2.9264 - val_loss: 2.0524 - val_mse: 2.0524\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.8174 - mse: 2.8174 - val_loss: 2.0349 - val_mse: 2.0349\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.7278 - mse: 2.7278 - val_loss: 2.1355 - val_mse: 2.1355\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.8774 - mse: 2.8774 - val_loss: 2.0017 - val_mse: 2.0017\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.7814 - mse: 2.7814 - val_loss: 1.9879 - val_mse: 1.9879\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.6961 - mse: 2.6961 - val_loss: 2.0192 - val_mse: 2.0192\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.5890 - mse: 2.5890 - val_loss: 2.0070 - val_mse: 2.0070\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.5822 - mse: 2.5822 - val_loss: 2.0542 - val_mse: 2.0542\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.5487 - mse: 2.5487 - val_loss: 1.9546 - val_mse: 1.9546\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.5046 - mse: 2.5046 - val_loss: 1.9005 - val_mse: 1.9005\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.4961 - mse: 2.4961 - val_loss: 1.8860 - val_mse: 1.8860\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.5760 - mse: 2.5760 - val_loss: 1.9314 - val_mse: 1.9314\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.4633 - mse: 2.4633 - val_loss: 1.8324 - val_mse: 1.8324\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.4183 - mse: 2.4183 - val_loss: 1.9013 - val_mse: 1.9013\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.3903 - mse: 2.3903 - val_loss: 1.7912 - val_mse: 1.7912\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.3689 - mse: 2.3689 - val_loss: 1.8066 - val_mse: 1.8066\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.4024 - mse: 2.4024 - val_loss: 1.8433 - val_mse: 1.8433\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.3618 - mse: 2.3618 - val_loss: 1.7603 - val_mse: 1.7603\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.3104 - mse: 2.3104 - val_loss: 1.7729 - val_mse: 1.7729\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.3334 - mse: 2.3334 - val_loss: 1.7442 - val_mse: 1.7442\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.2822 - mse: 2.2822 - val_loss: 1.7104 - val_mse: 1.7104\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.4185 - mse: 2.4185 - val_loss: 1.7239 - val_mse: 1.7239\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.3126 - mse: 2.3126 - val_loss: 1.7340 - val_mse: 1.7340\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.3839 - mse: 2.3839 - val_loss: 1.7670 - val_mse: 1.7670\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.1680 - mse: 2.1680 - val_loss: 1.6364 - val_mse: 1.6364\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.2110 - mse: 2.2110 - val_loss: 1.6203 - val_mse: 1.6203\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.1540 - mse: 2.1540 - val_loss: 1.6998 - val_mse: 1.6998\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.2099 - mse: 2.2099 - val_loss: 1.5860 - val_mse: 1.5860\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.3978 - mse: 2.3978\n",
      "loss:  2.397761821746826\n",
      "accuracy:  2.397761821746826\n"
     ]
    }
   ],
   "source": [
    "#Example Multiple Layer Perceptron Classification\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "whole_data = load_breast_cancer()\n",
    "\n",
    "X_data = whole_data.data\n",
    "y_data = whole_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3, random_state = 7)\n",
    "features = X_train.shape[1]\n",
    "#MPL 3-layer Model ==============================================\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10, activation='relu', input_shape=[X_train.shape[1]]))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "print(model.summary())\n",
    "print(model.get_config())\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['mse'])\n",
    "model.fit(X_train, y_train, batch_size = 50, validation_split=0.2, epochs = 100, verbose = 1)\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('loss: ', results[0])\n",
    "print('accuracy: ', results[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd79893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
